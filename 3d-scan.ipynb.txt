{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14571585,"sourceType":"datasetVersion","datasetId":9307946}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nimport sys\nimport glob\nimport subprocess\nfrom pathlib import Path\nimport json\nimport torch\n\n# ================= CONFIGURATION =================\nPROJECT_NAME = \"car_scan\"\n# IMPORTANT: Update this path to match your uploaded video in Kaggle\nVIDEO_INPUT_PATH = '/kaggle/input/car-video/video_car.mp4' \nWORKING_DIR = \"/kaggle/working\"\nPROJECT_DIR = f\"{WORKING_DIR}/{PROJECT_NAME}\"\nDATABASE_PATH = f\"{PROJECT_DIR}/database.db\"\nIMAGES_DIR = f\"{PROJECT_DIR}/images\"\nSPARSE_PATH = f\"{PROJECT_DIR}/sparse\"\nOUTPUTS_DIR = f\"{WORKING_DIR}/outputs/{PROJECT_NAME}/splatfacto\"\n\ndef run_command(cmd, shell=False):\n    \"\"\"Runs a shell command and raises an exception if it fails.\"\"\"\n    print(f\"üöÄ Running: {cmd}\")\n    try:\n        if shell:\n            subprocess.run(cmd, shell=True, check=True)\n        else:\n            # Split command string into list if it's not already, unless shell=True\n            if isinstance(cmd, str) and not shell:\n                cmd = cmd.split()\n            subprocess.run(cmd, check=True)\n    except subprocess.CalledProcessError as e:\n        print(f\"‚ùå Command failed: {cmd}\")\n        raise e\n\ndef check_gpu():\n    print(\"üîç Checking GPU availability...\")\n    if not torch.cuda.is_available():\n        print(\"‚ö†Ô∏è\" * 20)\n        print(\"‚ö†Ô∏è WARNING: GPU Not Detected!\")\n        print(\"‚ö†Ô∏è This script requires a GPU (P100 or T4) to run effectively.\")\n        print(\"‚ö†Ô∏è Please enable GPU Accelerator in your Kaggle Notebook settings.\")\n        print(\"‚ö†Ô∏è\" * 20)\n        return False\n    print(f\"‚úÖ GPU Detected: {torch.cuda.get_device_name(0)}\")\n    return True\n\ndef install_dependencies():\n    print(\"‚è≥ Installing dependencies...\")\n    run_command(\"pip install --upgrade pip\", shell=True)\n    run_command(\"pip install torch torchvision\", shell=True)\n    run_command(\"pip install nerfstudio\", shell=True)\n    \n    print(\"‚è≥ Installing COLMAP & ffmpeg...\")\n    run_command(\"apt-get update\", shell=True)\n    \n    # --- FIX 1: Use mamba for COLMAP (More stable on Kaggle) ---\n    try:\n        print(\"   Attempting to install COLMAP via mamba...\")\n        run_command(\"mamba install -y -c conda-forge colmap\", shell=True)\n    except Exception as e:\n        print(\"‚ö†Ô∏è Mamba install failed, falling back to apt-get...\")\n        run_command(\"apt-get install -y colmap\", shell=True)\n        \n    run_command(\"apt-get install -y ffmpeg xvfb\", shell=True)\n    \n    try:\n        run_command(\"colmap help\", shell=True)\n        print(\"‚úÖ COLMAP installed successfully.\")\n    except:\n        print(\"‚ùå COLMAP installation failed.\")\n\ndef patch_nerfstudio():\n    \"\"\"\n    Patches nerfstudio installed in the system to fix PyTorch 2.6+ compatibility issues.\n    \"\"\"\n    print(\"üîß Patching nerfstudio for PyTorch 2.6+ compatibility...\")\n    try:\n        # Find the installed nerfstudio package\n        potential_paths = glob.glob(\"/usr/local/lib/python*/dist-packages/nerfstudio/utils/eval_utils.py\")\n        if not potential_paths:\n            # Fallback for some environments\n            potential_paths = glob.glob(\"/opt/conda/lib/python*/site-packages/nerfstudio/utils/eval_utils.py\")\n            \n        if potential_paths:\n            target_file = Path(potential_paths[0])\n            print(f\"   Found file: {target_file}\")\n            \n            with open(target_file, \"r\") as f:\n                content = f.read()\n            \n            # The specific line causing the issue\n            old_code = 'loaded_state = torch.load(load_path, map_location=\"cpu\")'\n            # The fix: disable weights_only security check for trust-based loading\n            new_code = 'loaded_state = torch.load(load_path, map_location=\"cpu\", weights_only=False)'\n            \n            if old_code in content:\n                new_content = content.replace(old_code, new_code)\n                with open(target_file, \"w\") as f:\n                    f.write(new_content)\n                print(\"‚úÖ Patch applied successfully!\")\n            elif 'weights_only=False' in content:\n                 print(\"‚úÖ Patch was already applied.\")\n            else:\n                print(f\"‚ö†Ô∏è Target code not found in {target_file}. The library version might be different.\")\n        else:\n            print(\"‚ö†Ô∏è Could not locate nerfstudio/utils/eval_utils.py to patch.\")\n    except Exception as e:\n        print(f\"‚ùå Failed to patch nerfstudio: {e}\")\n\ndef process_data():\n    if not os.path.exists(VIDEO_INPUT_PATH):\n        print(f\"‚ùå Error: Video file not found at {VIDEO_INPUT_PATH}\")\n        print(\"Please upload your video and update VIDEO_INPUT_PATH in the script.\")\n        return False\n\n    print(\"--- 1. Clean & Setup ---\")\n    if os.path.exists(f\"{PROJECT_DIR}\"):\n        shutil.rmtree(f\"{PROJECT_DIR}\")\n    os.makedirs(f\"{PROJECT_DIR}\", exist_ok=True)\n    os.makedirs(IMAGES_DIR, exist_ok=True)\n\n    print(\"--- 2. Downscale Video ---\")\n    downscaled_video = f\"{WORKING_DIR}/{PROJECT_NAME}_downscaled.mp4\"\n    # Added -pix_fmt yuv420p for better compatibility\n    run_command(f\"ffmpeg -y -i \\\"{VIDEO_INPUT_PATH}\\\" -vf scale='iw/2:ih/2' -c:v libx264 -preset ultrafast -crf 23 -c:a copy \\\"{downscaled_video}\\\"\", shell=True)\n\n    print(\"--- 3. Extract Frames (2 FPS) ---\")\n    run_command(f\"ffmpeg -y -i \\\"{downscaled_video}\\\" -vf \\\"fps=2\\\" \\\"{IMAGES_DIR}/frame_%05d.png\\\" -hide_banner -loglevel error\", shell=True)\n    \n    num_images = len(os.listdir(IMAGES_DIR))\n    print(f\"‚úÖ Extracted {num_images} images.\")\n\n    print(\"--- 4. Feature Extraction ---\")\n    # Using CPU for feature extraction as per original notebook config\n    cmd_extract = [\n        \"colmap\", \"feature_extractor\",\n        \"--database_path\", DATABASE_PATH,\n        \"--image_path\", IMAGES_DIR,\n        \"--ImageReader.camera_model\", \"OPENCV\",\n        \"--SiftExtraction.use_gpu\", \"0\",\n        \"--SiftExtraction.num_threads\", \"16\",\n        \"--SiftExtraction.peak_threshold\", \"0.004\",\n    ]\n    run_command(\" \".join(cmd_extract), shell=True)\n\n    print(\"--- 5. Matching (Sequential) ---\")\n    # --- FIX 2: Disable loop_detection to avoid crash due to missing vocab tree ---\n    cmd_match = [\n        \"colmap\", \"sequential_matcher\",\n        \"--database_path\", DATABASE_PATH,\n        \"--SiftMatching.use_gpu\", \"1\",\n        \"--SequentialMatching.loop_detection\", \"0\", # Changed from 1 to 0\n        \"--SequentialMatching.overlap\", \"10\"\n    ]\n    run_command(\" \".join(cmd_match), shell=True)\n\n    print(\"--- 6. Mapper (Relaxed) ---\")\n    os.makedirs(SPARSE_PATH, exist_ok=True)\n    cmd_mapper = [\n        \"colmap\", \"mapper\",\n        \"--database_path\", DATABASE_PATH,\n        \"--image_path\", IMAGES_DIR,\n        \"--output_path\", SPARSE_PATH,\n        \"--Mapper.min_num_matches\", \"10\",\n        \"--Mapper.init_min_tri_angle\", \"2\",\n        \"--Mapper.multiple_models\", \"0\"\n    ]\n    run_command(\" \".join(cmd_mapper), shell=True)\n\n    print(\"--- 7. Converting to transforms.json ---\")\n    recon_dir = Path(f\"{SPARSE_PATH}/0\")\n    if not recon_dir.exists():\n        print(\"‚ùå FAILED: Sparse reconstruction failed. No model found.\")\n        return False\n    \n    from nerfstudio.process_data.colmap_utils import colmap_to_json\n    colmap_to_json(\n        recon_dir=recon_dir,\n        output_dir=Path(PROJECT_DIR),\n    )\n    \n    if os.path.exists(f\"{PROJECT_DIR}/transforms.json\"):\n        print(\"‚úÖ transforms.json created.\")\n        return True\n    else:\n        print(\"‚ùå Failed to create transforms.json\")\n        return False\n\ndef train_model():\n    print(\"--- Training Splatfacto Model ---\")\n    # ns-train splatfacto --data {PROJECT_DIR} --viewer.quit-on-train-completion True\n    cmd_train = f\"ns-train splatfacto --data \\\"{PROJECT_DIR}\\\" --viewer.quit-on-train-completion True\"\n    run_command(cmd_train, shell=True)\n\ndef export_model():\n    print(\"--- Exporting .splat ---\")\n    training_output_path = Path(OUTPUTS_DIR)\n    \n    if not training_output_path.exists():\n        print(f\"‚ùå Error: Training output directory not found at {training_output_path}\")\n        return\n\n    subfolders = [f for f in training_output_path.iterdir() if f.is_dir()]\n    if not subfolders:\n        print(\"‚ùå Error: No training run folders found.\")\n        return\n\n    latest_run = max(subfolders, key=os.path.getmtime)\n    config_path = latest_run / \"config.yml\"\n    \n    if not config_path.exists():\n        print(f\"‚ùå Error: Config file not found in {latest_run}\")\n        return\n        \n    print(f\"‚úÖ Found latest config: {config_path}\")\n    \n    # Run export\n    cmd_export = f\"ns-export gaussian-splat --load-config \\\"{config_path}\\\" --output-dir \\\"{latest_run}\\\"\"\n    run_command(cmd_export, shell=True)\n    \n    # Verify result\n    generated_splats = list(latest_run.glob(\"*.splat\"))\n    if generated_splats:\n        print(f\"üéâ SUCCESS! Exported file: {generated_splats[0]}\")\n    else:\n        print(\"‚ùå Export command finished but no .splat file was found.\")\n\ndef main():\n    # 1. GPU Check\n    if not check_gpu():\n        # Depending on preference, might want to exit here or continue with warning\n        pass \n\n    # 2. Install Deps\n    install_dependencies()\n    \n    # 3. Apply Patch (Critical Fix)\n    patch_nerfstudio()\n    \n    # 4. Process Data\n    if process_data():\n        # 5. Train\n        train_model()\n        \n        # 6. Export\n        export_model()\n\nif __name__ == \"__main__\":\n    # Ensure MAX_JOBS is set to avoid freezing\n    os.environ['MAX_JOBS'] = '1'\n    main()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}